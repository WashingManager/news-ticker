name: Embassy Status Scraper

on:
  workflow_dispatch: # 수동 실행 버튼
  schedule:
    # 한국 시간(KST) 기준 00:01, 06:01, 12:01, 18:01에 실행
    # (UTC 기준 15:01, 21:01, 03:01, 09:01)
    - cron: '1 3,9,15,21 * * *'

jobs:
  scrape-and-commit:
    runs-on: ubuntu-latest
    steps:
      # 1. 저장소 코드를 체크아웃
      - name: Check out repository
        uses: actions/checkout@v4

      # 2. Python 3.9 설정
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'

      # 3. Python 의존성 라이브러리 설치
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4

      # 4. 스크래핑 스크립트 실행
      - name: Run scraping script
        run: python scrape_embassy.py

      # 5. 변경된 JSON 파일이 있을 경우 자동으로 커밋
      - name: Commit and push if data changed
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: 'chore: Update embassy status data'
          file_pattern: 'embassy_status.json'
          commit_user_name: 'github-actions[bot]' # 커밋할 봇 이름
          commit_user_email: 'github-actions[bot]@users.noreply.github.com' # 봇 이메일
          commit_author: 'github-actions[bot] <github-actions[bot]@users.noreply.github.com>'
