import requests
from bs4 import BeautifulSoup
import json
import datetime

# ëª¨ë‹ˆí„°ë§í•  URL
URL = "https://embassywatch.gkuer.com/"

# ë°ì´í„°ë¥¼ ì €ì¥í•  JSON íŒŒì¼ ì´ë¦„
JSON_FILE = "embassy_status.json"
# ì •ìƒ êµ­ê°€ ëª©ë¡ì„ ì €ì¥í•  ì •ì  íŒŒì¼
NORMAL_LIST_FILE = "normal_countries.json" 

# [!! ì‹ ê·œ !!] íŒŒì´ì¬ìœ¼ë¡œ ì‹œê°„ í¬ë§·íŒ… (JS ë¡œì§ ë³µì œ)
def format_python_time(date_obj):
    """JSì˜ formatTime í•¨ìˆ˜ì™€ ë™ì¼í•˜ê²Œ KST ì‹œê°„ ê°ì²´ë¥¼ í¬ë§·íŒ…í•©ë‹ˆë‹¤."""
    y = date_obj.year
    m = date_obj.month
    d = date_obj.day
    h = date_obj.hour
    
    is_am = h < 12
    period = "ì˜¤ì „" if is_am else "ì˜¤í›„"
    
    h_12 = h % 12 or 12 # 0ì‹œë¥¼ 12ì‹œë¡œ ë³€ê²½
    
    # JS ë¡œì§ì€ 6ì‹œê°„ ë‹¨ìœ„ì´ë¯€ë¡œ ë¶„ì€ í•­ìƒ 00ì…ë‹ˆë‹¤.
    minutes_str = "00" 
    
    return f"{y}ë…„ {m}ì›” {d}ì¼ {period} {h_12}:{minutes_str}"

def scrape_embassy_status():
    print(f"[{datetime.datetime.now()}] ìŠ¤í¬ë˜í•‘ ì‹œì‘: {URL}")
    
    last_update_time = "" 
    
    # [!! ìˆ˜ì • !!] JS ë¡œì§ì„ Pythonìœ¼ë¡œ ì§ì ‘ ê³„ì‚° (ìŠ¤í¬ë˜í•‘ ëŒ€ì‹ )
    try:
        # 1. UTC ê¸°ì¤€ í˜„ì¬ ì‹œê°„
        now_utc = datetime.datetime.utcnow()
        # 2. KST (UTC+9)
        korea_time = now_utc + datetime.timedelta(hours=9)
        hour_kst = korea_time.hour
        
        # 3. ë§ˆì§€ë§‰ 6ì‹œê°„ ë‹¨ìœ„ ê³„ì‚° (0, 6, 12, 18ì‹œ)
        last_check_hour_kst = (hour_kst // 6) * 6
        
        # 4. ë§ˆì§€ë§‰ í™•ì¸ ì‹œê°„ ê°ì²´ ìƒì„± (ë¶„, ì´ˆ 0ìœ¼ë¡œ)
        last_check_time = korea_time.replace(hour=last_check_hour_kst, minute=0, second=0, microsecond=0)
        
        # 5. í¬ë§·íŒ…
        last_update_time = format_python_time(last_check_time)
        print(f"ì—…ë°ì´íŠ¸ ì‹œê°„ ê³„ì‚°ë¨: {last_update_time}")
        
    except Exception as e:
        print(f"ì˜¤ë¥˜: ì‹œê°„ ê³„ì‚° ì‹¤íŒ¨. {e}")
        last_update_time = "ì‹œê°„ ê³„ì‚° ì˜¤ë¥˜" # ì‹¤íŒ¨ ì‹œ

    # --- (ì´í•˜ êµ­ê°€ ëª©ë¡ ìŠ¤í¬ë˜í•‘) ---
    
    withdrawal_list = []
    normal_list = []
    output_data_list = [] # ìµœì¢… ì•„ì´í…œ ë¦¬ìŠ¤íŠ¸
    
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
        response = requests.get(URL, headers=headers, timeout=10)
        response.raise_for_status()
        response.encoding = 'utf-8'

        soup = BeautifulSoup(response.text, "html.parser")
        
        # --- êµ­ê°€ ëª©ë¡ ì²˜ë¦¬ ---
        country_items = soup.find_all("div", class_="country-item")
        
        if not country_items:
            print("ì˜¤ë¥˜: 'country-item' ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            # (ë¦¬ìŠ¤íŠ¸ëŠ” ë¹„ì–´ìˆëŠ” ìƒíƒœë¡œ ë‘ )
        else:
            for item in country_items:
                country = item.find("strong").get_text(strip=True).replace(":", "")
                item_text = item.get_text(strip=True)
                status_full_text = item_text.replace(country + ":", "").strip()

                if status_full_text == "ì² ìˆ˜ ì†Œì‹ ì—†ìŒ":
                    normal_list.append(country)
                else:
                    link_tag = item.find("a")
                    link_url = URL
                    
                    if link_tag and link_tag.get('href'):
                        link_url = link_tag.get('href')

                    status_description = status_full_text.split("í™•ì¸ëœ ë§í¬:")[0].strip()
                    if not status_description:
                        status_description = status_full_text

                    withdrawal_list.append({
                        "title": f"ğŸš¨ [ê¸´ê¸‰] {country} ëŒ€ì‚¬ê´€: {status_description}",
                        "status": "withdrawal",
                        "link": link_url
                    })

    except requests.exceptions.RequestException as e:
        print(f"ì˜¤ë¥˜: í˜ì´ì§€ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. {e}")
    except Exception as e:
        print(f"ì˜¤ë¥˜: ë°ì´í„° ì²˜ë¦¬ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. {e}")

    # --- ìµœì¢… JSON ë°ì´í„° ìƒì„± ---
    
    if withdrawal_list:
        # ê¸´ê¸‰ ìƒí™©ì´ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ê¸´ê¸‰ ëª©ë¡ë§Œ ì¶œë ¥
        print(f"!!! ê¸´ê¸‰ ìƒí™© ê°ì§€: {len(withdrawal_list)}ê°œêµ­")
        output_data_list = withdrawal_list
    elif normal_list:
        # ê¸´ê¸‰ ìƒí™©ì´ ì—†ê³ , ì •ìƒ ëª©ë¡ì´ ìˆìœ¼ë©´
        print(f"ëª¨ë“  ëŒ€ì‚¬ê´€ ì •ìƒ: {len(normal_list)}ê°œêµ­")
        
        # [!! ìˆ˜ì • !!] title í˜•ì‹ì„ ìš”ì²­í•˜ì‹  ëŒ€ë¡œ ë³€ê²½
        output_data_list = [{
            "title": f"{len(normal_list)}ê°œêµ­ ì£¼í•œ ëŒ€ì‚¬ê´€ ì² ìˆ˜ ì†Œì‹ ì—†ìŒ", 
            "status": "normal",
            "link": URL
        }]
        
        # ì •ìƒ êµ­ê°€ ëª©ë¡ì„ ë³„ë„ íŒŒì¼ë¡œ ì €ì¥
        try:
            with open(NORMAL_LIST_FILE, "w", encoding="utf-8") as f_countries:
                json.dump(normal_list, f_countries, ensure_ascii=False, indent=2)
            print(f"{NORMAL_LIST_FILE} íŒŒì¼ì— {len(normal_list)}ê°œêµ­ ëª©ë¡ ì €ì¥ ì™„ë£Œ.")
        except Exception as e:
            print(f"ì˜¤ë¥˜: {NORMAL_LIST_FILE} íŒŒì¼ ì €ì¥ ì‹¤íŒ¨. {e}")
    else:
        # ê¸´ê¸‰ ìƒí™©ë„ ì—†ê³ , ì •ìƒ ëª©ë¡ë„ ì—†ëŠ” ê²½ìš° (ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨ ë“±)
        print("ê²½ê³ : ìŠ¤í¬ë˜í•‘ëœ êµ­ê°€ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. (ì‚¬ì´íŠ¸ ë³€ê²½ ë˜ëŠ” ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨)")
        output_data_list = [{
            "title": "ëŒ€ì‚¬ê´€ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ",
            "status": "error",
            "link": URL
        }]

    # ìµœì¢… JSON ê°ì²´ ìƒì„± (ì‹œê°„ + ì•„ì´í…œ ëª©ë¡)
    final_json_output = {
        "lastUpdate": last_update_time,
        "items": output_data_list
    }

    # ìµœì¢… ê°ì²´ë¥¼ embassy_status.json íŒŒì¼ì— ì €ì¥
    with open(JSON_FILE, "w", encoding="utf-8") as f:
        json.dump(final_json_output, f, ensure_ascii=False, indent=2)
        
    print(f"[{datetime.datetime.now()}] ìŠ¤í¬ë˜í•‘ ì™„ë£Œ. {JSON_FILE} íŒŒì¼ ìƒì„±ë¨.")


if __name__ == "__main__":
    scrape_embassy_status()
